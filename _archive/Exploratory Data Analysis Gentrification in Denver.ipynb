{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gentrification in Denver\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Brittany Bennett\n",
    "July 2018 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Gentrification?  \n",
    "Gentrification is becoming more and more of an issue as we see disadvantages communities pushed out of their neighborhoods while housing prices soar. I moved to Denver right after graduation college in 2016 and saw first hand how the city is changing, for better or for worse. I lived in Denver's historically black neighborhood, Five Points. When I looked around my neighborhood, I saw middle class white families walking their dogs, upscale fried chicken restuarants, and an expensive cafe juxatposed against a family owned sould food restuarant, and old-school car repair shop, and derilict houses that lined Welton Street. \n",
    "\n",
    "Digging into the history of Five Points, it became apparent that the neighborhood has undergone a serious change in the past couple of years. The fancy fried chicken joint had replaced a family owned fried chicken joint. What used to be small, low cost shops were now breweries and yoga studios.  \n",
    "\n",
    "This all had devastating effects ont he black population of Five Points, who were driven out of their homes and further east where the cost of living was cheaper.  \n",
    "\n",
    "Regardless of your stance on gentrification, it will be valuable for developers and city officials to understand if a certain neighborhood is gentrifying. Being able to predict gentrification will allow appropriate parties to better plan for the future and potentially protect residents from being displaced.  \n",
    "\n",
    "### Methodology  \n",
    "I was primarily interested in how Denver had or had not gentrified since the legalization of marjiuana in 2014. Therefore, I decided to look at the change in Dnever from 2011 to 2016.  \n",
    "\n",
    "I used the following formula to determine if a census tract had gentrified or not. I compared census data from 2011 with census data from 2016 to make my decision. From Wikipedia:  \n",
    "\n",
    "\"Whether gentrification has occurred in a census tract in an urban area in the United States during a particular 10-year period between censuses can be determined by a method used in a study by Governing:[50] If the census tract in a central city had 500 or more residents and at the time of the baseline census  \n",
    "<li> had median household income and median home value in the bottom 40th percentile and at the time of the next 10-year census the \n",
    "<li>tract's educational attainment (percentage of residents over age 25 with a bachelor's degree) was in the top 33rd percentile; \n",
    "<li>the median home value, adjusted for inflation, had increased;   \n",
    "<li>and the percentage of increase in home values in the tract was in the top 33rd percentile when compared to the increase in other census tracts in the urban area  \n",
    "then it was considered to have been gentrified.\n",
    "\n",
    "I used this formula to determine which census tracts in Denver have gentrified from 2011 to 2016. \n",
    "\n",
    "To build a predicative model of gentrification, I theorized some variable I believed were early signs of gentrification. I narrowed down my list to the two variables I believed were the biggest signs: new expensive restaurants and new cafes.  \n",
    "\n",
    "To build upon this study, I suggest also looking at the opening of art galleries and other institutions relting to art. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.cm\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Below we read in each table from the American Communities Survey for the years\n",
    "# 2011 and 2016 and add them each to a separate pandas data frame. Later we will merge these\n",
    "# individual data frames into 2011 and 2016 data frames. \n",
    "\n",
    "### Education\n",
    "education_2011 = pd.read_csv(\"data/2011/2011_education.csv\",index_col=None, skiprows = [1], header=0)\n",
    "#Total; Estimate; Percent bachelor's degree or higher (25+ year old)\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\",\"HC01_EST_VC17\"]\n",
    "education_2011 = education_2011[keep_these]\n",
    "\n",
    "education_2016 = pd.read_csv(\"data/2016/2016_education.csv\",index_col=None, skiprows = [1], header=0)\n",
    "#  Percent; Estimate; Percent bachelor's degree or higher (25+ year old)\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\",\"HC02_EST_VC18\"]\n",
    "education_2016 = education_2016[keep_these]\n",
    "\n",
    "### Housing\n",
    "housing_2011 = pd.read_csv(\"data/2011/2011_housing.csv\",index_col=None, skiprows = [1], header=0)\n",
    "# Estimate; VALUE - Median (dollars)\n",
    "# Estimate; GROSS RENT - Median (dollars) HC01_VC185\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\",\"HC01_VC125\"]\n",
    "housing_2011 = housing_2011[keep_these]\n",
    "\n",
    "\n",
    "housing_2016 = pd.read_csv(\"data/2016/2016_housing.csv\",index_col=None, skiprows = [1], header=0)\n",
    "# Estimate; VALUE - Median (dollars)\n",
    "# Estimate; GROSS RENT - Median (dollars) HC01_VC191\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\",\"HC01_VC128\"]\n",
    "housing_2016 = housing_2016[keep_these]\n",
    "\n",
    "### Income\n",
    "income_2011 = pd.read_csv(\"data/2011/2011_income.csv\",index_col=None, skiprows = [1], header=0)\n",
    "#Median Household Income (Past 12 months)\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\",\"HD01_VD01\"]\n",
    "income_2011 = income_2011[keep_these]\n",
    "\n",
    "\n",
    "income_2016 = pd.read_csv(\"data/2016/2016_income.csv\",index_col=None, skiprows = [1], header=0)\n",
    "#Median Household Income (Past 12 months)\n",
    "keep_these = [\"GEO.id2\", \"GEO.display-label\", \"HD01_VD01\"]\n",
    "income_2016 = income_2016[keep_these]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbenn\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\bbenn\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Merge the education, housing, and median income data sets into one dataframe for 2011\n",
    "df_2011 = income_2011.merge(education_2011, on=[\"GEO.id2\", \"GEO.display-label\"], how = \"outer\")\n",
    "df_2011 = df_2011.merge(housing_2011, on=[\"GEO.id2\", \"GEO.display-label\"], how = \"outer\")\n",
    "df_2011.columns = [\"geo_id\", \"tract\", \"median_income\", \"percent_bachelors\", \"median_household_value\"]\n",
    "df_2011 = df_2011.drop(df_2011.index[143])\n",
    "df_2011 = df_2011.replace(\"-\", np.nan)\n",
    "df_2011[\"median_income\"] = df_2011[\"median_income\"].astype(float)\n",
    "df_2011[\"median_household_value\"] = df_2011[\"median_household_value\"].astype(float)\n",
    "\n",
    "## Merge the education, housing, and median income data sets into one dataframe for 2016\n",
    "df_2016 = income_2016.merge(education_2016, on=[\"GEO.id2\", \"GEO.display-label\"], how = \"outer\")\n",
    "df_2016 = df_2016.merge(housing_2016, on=[\"GEO.id2\", \"GEO.display-label\"], how = \"outer\")\n",
    "df_2016.columns = [\"geo_id\", \"tract\", \"median_income\", \"percent_bachelors\", \"median_household_value\"]\n",
    "df_2016 = df_2016.drop(df_2016.index[143])\n",
    "df_2016 = df_2016.replace(\"-\", np.nan)\n",
    "df_2016[\"percent_bachelors\"] = df_2016[\"percent_bachelors\"].astype(float)\n",
    "df_2016[\"median_household_value\"] = df_2016[\"median_household_value\"].astype(float)\n",
    "\n",
    "## Inialize a data frame to store gentrification varialbes\n",
    "gentrification = df_2011[[\"geo_id\", \"tract\"]]\n",
    "\n",
    "## Create the first gentrification variable: bottom 40th percentile in median income for 2011 census data\n",
    "bottom_40_income = np.nanpercentile(df_2011[\"median_income\"],40)\n",
    "\n",
    "gent_1 = []\n",
    "for row in df_2011.median_income:\n",
    "    if row <= bottom_40_income:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    gent_1.append(val)\n",
    "gentrification[\"gent_1\"] = gent_1\n",
    "\n",
    "## Create the second gentrification variable: bottom 40th percentile median household value for 2011 census data\n",
    "bottom_40_value = np.nanpercentile(df_2011[\"median_household_value\"],40)\n",
    "gent_2 = []\n",
    "for row in df_2011.median_household_value:\n",
    "    if row <= bottom_40_value:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    gent_2.append(val)\n",
    "gentrification[\"gent_2\"] = gent_2\n",
    "        \n",
    "## Create the third gentrification variable: Top 30th percentile educational attainment for 2016 census data\n",
    "top_third_education = np.nanpercentile(df_2016[\"percent_bachelors\"],66)\n",
    "gent_3 = []\n",
    "for row in df_2016.percent_bachelors:\n",
    "    if row >= top_third_education:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    gent_3.append(val)\n",
    "gentrification[\"gent_3\"] = gent_3\n",
    "\n",
    "## Create the fourth gentrification variable: Top third median household value for 2016 census data\n",
    "top_third_housing = np.nanpercentile(df_2016[\"median_household_value\"],66)\n",
    "gent_4 = []\n",
    "for row in df_2016.median_household_value :\n",
    "    if row >= top_third_housing:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    gent_4.append(val)\n",
    "gentrification[\"gent_4\"] = gent_4\n",
    "\n",
    "## Determine if a census tract has gentrifed given a tweaked formula from the one above\n",
    "is_gent = []\n",
    "for index, row in gentrification.iterrows():\n",
    "    if ((row[2]+ row[3]) >= 1 & (row[4] + row[5]) >= 1):\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0 \n",
    "    is_gent.append(val)\n",
    "gentrification[\"is_gent\"] = is_gent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Find \"new\" expensive restaurants \n",
    "parameters = {'latitude': 39.768716, 'longitude': -105.026900, 'radius': 20000, 'price': '3,4', 'term': 'restaurant', 'limit': 50}\n",
    "headers = {'Authorization' : 'Bearer Cr3N0R8vGEsIr4HyZUX89lAaD_LTPlfWXTtVXU1RRLzepCSa7zMAUHxwZpQ1q_xXkQFwpk0QzteQVoOSaTIE8bQ9yHzYbpl0MAax910cQoCZtuoAe2C5gG9ot3ETW3Yx' }\n",
    "one = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "one = json.loads(one.content)\n",
    "\n",
    "\n",
    "parameters = {'latitude': 39.701069, 'longitude':-105.025398, 'radius': 20000, 'price': '3,4', 'term': 'restaurant', 'limit': 50}\n",
    "two = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "two = json.loads(two.content)\n",
    "\n",
    "parameters = {'latitude': 39.794333, 'longitude':  -104.805682, 'radius': 20000, 'price': '3,4', 'term': 'restaurant', 'limit': 50}\n",
    "three = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "three = json.loads(three.content)\n",
    "\n",
    "\n",
    "names_one = json_normalize(one, 'businesses')['name']\n",
    "names_two = json_normalize(two, 'businesses')['name']\n",
    "names_three = json_normalize(three, 'businesses')['name']\n",
    "\n",
    "one_lat =[]\n",
    "one_lon = []\n",
    "for i in json_normalize(one, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    one_lat.append(lat)\n",
    "    one_lon.append(lon)\n",
    "    \n",
    "two_lat =[]\n",
    "two_lon = []\n",
    "for i in json_normalize(two, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    two_lat.append(lat)\n",
    "    two_lon.append(lon)\n",
    "    \n",
    "three_lat =[]\n",
    "three_lon = []\n",
    "for i in json_normalize(three, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    three_lat.append(lat)\n",
    "    three_lon.append(lon)\n",
    "\n",
    "one = {'name': names_one, 'lat': one_lat, 'lon': one_lon}\n",
    "one_df = pd.DataFrame(data = one)\n",
    "\n",
    "two = {'name': names_two, 'lat': two_lat, 'lon': two_lon}\n",
    "two_df = pd.DataFrame(data = two)\n",
    "\n",
    "three = {'name': names_three, 'lat': three_lat, 'lon': three_lon}\n",
    "three_df = pd.DataFrame(data = three)\n",
    "\n",
    "restaurants = pd.concat([one_df, two_df, three_df])\n",
    "restaurants = restaurants.drop_duplicates()\n",
    "restaurants.to_csv('restaurants.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "restaurants = pd.read_csv(\"restaurants_complete.csv\")\n",
    "new_rest = restaurants.loc[restaurants['year'] <= 2014]\n",
    "num_new_rest = new_rest.groupby('tract', as_index=False)['name'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#####################################################################################################\n",
    "\n",
    "## Find \"new\" expensive coffee shops \n",
    "\n",
    "parameters = {'latitude': 39.768716, 'longitude': -105.026900, 'radius': 10000, 'price': '2,3,4', 'categories': 'coffee', 'limit': 50}\n",
    "headers = {'Authorization' : 'Bearer Cr3N0R8vGEsIr4HyZUX89lAaD_LTPlfWXTtVXU1RRLzepCSa7zMAUHxwZpQ1q_xXkQFwpk0QzteQVoOSaTIE8bQ9yHzYbpl0MAax910cQoCZtuoAe2C5gG9ot3ETW3Yx' }\n",
    "one = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "one = json.loads(one.content)\n",
    "\n",
    "\n",
    "parameters = {'latitude': 39.701069, 'longitude':-105.025398, 'radius': 10000, 'price': '2,3,4', 'categories': 'coffee', 'limit': 50}\n",
    "two = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "two = json.loads(two.content)\n",
    "\n",
    "parameters = {'latitude': 39.794333, 'longitude':  -104.805682, 'radius': 5000, 'price': '2,3,4', 'categories': 'coffee', 'limit': 50}\n",
    "three = requests.get(\"https://api.yelp.com/v3/businesses/search\", params = parameters, headers=headers)\n",
    "three = json.loads(three.content)\n",
    "\n",
    "one['total']\n",
    "two['total']\n",
    "three['total']\n",
    "\n",
    "\n",
    "names_one = json_normalize(one, 'businesses')['name']\n",
    "names_two = json_normalize(two, 'businesses')['name']\n",
    "names_three = json_normalize(three, 'businesses')['name']\n",
    "\n",
    "one_lat =[]\n",
    "one_lon = []\n",
    "for i in json_normalize(one, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    one_lat.append(lat)\n",
    "    one_lon.append(lon)\n",
    "    \n",
    "two_lat =[]\n",
    "two_lon = []\n",
    "for i in json_normalize(two, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    two_lat.append(lat)\n",
    "    two_lon.append(lon)\n",
    "    \n",
    "three_lat =[]\n",
    "three_lon = []\n",
    "for i in json_normalize(three, 'businesses')['coordinates']:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    three_lat.append(lat)\n",
    "    three_lon.append(lon)\n",
    "\n",
    "one = {'name': names_one, 'lat': one_lat, 'lon': one_lon}\n",
    "one_df = pd.DataFrame(data = one)\n",
    "\n",
    "two = {'name': names_two, 'lat': two_lat, 'lon': two_lon}\n",
    "two_df = pd.DataFrame(data = two)\n",
    "\n",
    "three = {'name': names_three, 'lat': three_lat, 'lon': three_lon}\n",
    "three_df = pd.DataFrame(data = three)\n",
    "\n",
    "cafes = pd.concat([one_df, two_df, three_df])\n",
    "cafes = cafes.drop_duplicates()\n",
    "\n",
    "cafes.to_csv('cafes.csv', encoding='utf-8')\n",
    "\n",
    "cafes = pd.read_csv(\"cafes_complete.csv\")\n",
    "new_cafes = cafes.loc[cafes['year'] <= 2014]\n",
    "\n",
    "new_cafes.to_csv('new_cafes.csv', encoding='utf-8')\n",
    "new_rest.to_csv('new_rest.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "num_new_cafes = new_cafes.groupby('tract', as_index=False)['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_new_cafes.columns = [\"tract\", \"cafes\"]\n",
    "num_new_rest.columns = [\"tract\", \"rest\"]\n",
    "\n",
    "predict_df = pd.merge(num_new_cafes, num_new_rest, on = \"tract\", how =\"outer\")\n",
    "\n",
    "gentrified_census_tracts = gentrification.loc[gentrification[\"is_gent\"] == 1]\n",
    "gentrified_census_tracts = gentrified_census_tracts.iloc[:,[0,6]]\n",
    "gentrified_census_tracts.columns = [\"tract\", \"is_gent\"]\n",
    "\n",
    "df = pd.merge(predict_df, gentrified_census_tracts, on= \"tract\", how =\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis \n",
    "Are census tracts with more new cafes and restaurants more prone to gentrification 5 years later?  \n",
    "**H0:** There is not a significant difference in the number of new cafes and restaurants started up around 2011 for census tracts that have been shown to gentrify by 2016 in Denver.  \n",
    "**HA:** There IS a significant difference in the number of new cafes and restaurants started up around 2011 for census stracts that have been shown to gentrify by 2016 in Denver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract</th>\n",
       "      <th>cafes</th>\n",
       "      <th>rest</th>\n",
       "      <th>is_gent</th>\n",
       "      <th>new_places</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8031000301</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8031000303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8031000401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8031001102</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8031001701</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8031001702</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8031001800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8031002402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8031002802</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8031003001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8031003003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8031003203</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8031003401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8031003402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8031003800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8031001901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8031002602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8031002702</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8031002901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8031004107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8031980100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8031000502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8031002703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8031003201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8031006812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tract  cafes  rest  is_gent  new_places\n",
       "0   8031000301      2     0        0           2\n",
       "1   8031000303      1     1        0           2\n",
       "2   8031000401      1     0        0           1\n",
       "3   8031001102      1     4        0           5\n",
       "4   8031001701      7    11        0          18\n",
       "5   8031001702      1     6        0           7\n",
       "6   8031001800      1     0        0           1\n",
       "7   8031002402      1     0        0           1\n",
       "8   8031002802      1     1        0           2\n",
       "9   8031003001      1     2        0           3\n",
       "10  8031003003      1     0        0           1\n",
       "11  8031003203      2     1        0           3\n",
       "12  8031003401      1     0        0           1\n",
       "13  8031003402      1     0        0           1\n",
       "14  8031003800      1     2        0           3\n",
       "15  8031001901      0     1        0           1\n",
       "16  8031002602      0     1        0           1\n",
       "17  8031002702      0     1        1           1\n",
       "18  8031002901      0     1        0           1\n",
       "19  8031004107      0     1        0           1\n",
       "20  8031980100      0     1        0           1\n",
       "21  8031000502      0     0        1           0\n",
       "22  8031002703      0     0        1           0\n",
       "23  8031003201      0     0        1           0\n",
       "24  8031006812      0     0        1           0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_places\"] = df.cafes+df.rest\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract</th>\n",
       "      <th>cafes</th>\n",
       "      <th>rest</th>\n",
       "      <th>is_gent</th>\n",
       "      <th>new_places</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8031002702</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8031000502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8031002703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8031003201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8031006812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tract  cafes  rest  is_gent  new_places\n",
       "17  8031002702      0     1        1           0\n",
       "21  8031000502      0     0        1           0\n",
       "22  8031002703      0     0        1           0\n",
       "23  8031003201      0     0        1           0\n",
       "24  8031006812      0     0        1           0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gent = df.loc[df[\"is_gent\"] == 1]\n",
    "not_gent = df.loc[df[\"is_gent\"] == 0]\n",
    "gent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('p =', 0.39091999999999999)\n"
     ]
    }
   ],
   "source": [
    "diff_of_means = np.abs(np.mean(gent.new_places) - np.mean(not_gent.new_places))\n",
    "\n",
    "permutation_replicates = np.empty(100000)\n",
    "\n",
    "for i in range(len(permutation_replicates)):\n",
    "    permutation_samples = np.random.permutation(np.concatenate((gent.new_places, not_gent.new_places)))\n",
    "    \n",
    "    gent_perm = permutation_samples[:len(gent.new_places)]\n",
    "    not_gent_perm = permutation_samples[len(not_gent.new_places):]\n",
    "    \n",
    "    permutation_replicates[i] = np.abs(np.mean(gent_perm) - np.mean(not_gent_perm))\n",
    "\n",
    "p = np.sum(permutation_replicates > diff_of_means) / len(permutation_replicates)\n",
    "print('p =', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The margin of error is', 1.80849169199087)\n",
      "('The 95% confidence interval is', [0.3415083080091299, 3.9584916919908699])\n"
     ]
    }
   ],
   "source": [
    "SE = np.sqrt(np.std(gent.new_places) ** 2 / len(gent.new_places) + np.std(not_gent.new_places) ** 2 / len(not_gent.new_places))\n",
    "\n",
    "margin_of_error = 1.96 * SE\n",
    "\n",
    "confidence_interval = [diff_of_means- margin_of_error, diff_of_means + margin_of_error]\n",
    "\n",
    "\n",
    "print('The margin of error is', margin_of_error)\n",
    "print('The 95% confidence interval is', confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "There is NOT significant difference in the number of new places in a census tract that does gentrify. The alpha og 0.307 >>> 0.05, so we cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
